{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04b86ea9-2f3f-42ef-bc3e-7c4126756ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a01dde77-8d19-401e-bd09-33125afd0e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    X = torch.rand(20, 5)\n",
    "    y = torch.matmul(X, torch.tensor([0.3, 4.0, 0.2, 2.5, 18.0])) + 17.0\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f3f62e0-ce1a-4496-9fc2-1c3aac2ccefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da8179a7-d3c0-4d40-b69c-41cef4f9240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape=torch.Size([20, 5]) y.shape=torch.Size([20])\n",
      "loss=tensor(880.1790, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(872.0485, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(863.9950, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(856.0178, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(848.1162, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(840.2894, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(832.5369, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(824.8579, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(817.2516, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(809.7174, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X, y = get_dataset()\n",
    "print(f'{X.shape=}', f'{y.shape=}')\n",
    "model = MyModel()\n",
    "\n",
    "lr = 1e-3 # learing rate\n",
    "\n",
    "for epoch in range(10):\n",
    "    output = model(X)\n",
    "    assert output.shape == torch.Size((20, 1))\n",
    "    loss = F.mse_loss(output.squeeze(), y) # the target (y) is the second parameter (yes in scikit-learn it is the other way around)\n",
    "    print(f'{loss=}')\n",
    "    for parameter in model.parameters():\n",
    "        parameter.grad = None\n",
    "    loss.backward() # send the grads to the model's parameters\n",
    "    for parameter in model.parameters():\n",
    "        parameter.data -= lr * parameter.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe9788-27ba-47c4-b69b-96a5b9ff40a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
