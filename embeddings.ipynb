{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7d3b60-cb7d-419f-b28a-2839e3cf2c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55861e26-fffd-4540-ad51-0e223809f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(in_features=5, out_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd8bae1-dc4d-4f0e-b53c-d31393075026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2541, -1.0369,  0.1235, -0.2310,  0.8437,  0.1770,  0.5431, -0.1756,\n",
      "          0.2950, -0.1223],\n",
      "        [-0.0545, -0.8832,  0.1278,  0.2958,  0.5144, -0.0134,  0.1857, -0.4612,\n",
      "          0.2857, -0.6853]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand((30, 5))\n",
    "output = linear(input)\n",
    "\n",
    "print(output[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46506eac-9fc6-4939-9327-c7df9344d4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.9294\n",
      "Epoch [2/5], Loss: 0.9290\n",
      "Epoch [3/5], Loss: 0.9259\n",
      "Epoch [4/5], Loss: 0.9223\n",
      "Epoch [5/5], Loss: 0.9214\n",
      "Epoch [6/5], Loss: 0.9255\n",
      "Epoch [7/5], Loss: 0.9264\n",
      "Epoch [8/5], Loss: 0.9190\n",
      "Epoch [9/5], Loss: 0.9248\n",
      "Epoch [10/5], Loss: 0.9229\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the autoencoder class\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 6)  # Bottleneck layer\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(6, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28 * 28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Load the dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):  # Train for 5 epochs\n",
    "    for data in trainloader:\n",
    "        inputs, _ = data\n",
    "        inputs = inputs.view(-1, 28 * 28)  # Flatten the images\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/5], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "015b1227-6528-4c55-8f14-939229cbf58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  category  category_index\n",
      "0      cat               1\n",
      "1      dog               2\n",
      "2     bird               0\n",
      "3      cat               1\n",
      "4     bird               0\n",
      "5      dog               2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example categorical column\n",
    "data = {'category': ['cat', 'dog', 'bird', 'cat', 'bird', 'dog']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a unique index for each category\n",
    "df['category_index'] = df['category'].astype('category').cat.codes\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa9945b5-06cf-4eb3-b334-3c6d0ac3a683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 0],\n",
      "        [0, 0, 1],\n",
      "        [1, 0, 0],\n",
      "        [0, 1, 0],\n",
      "        [1, 0, 0],\n",
      "        [0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Convert category indices to one-hot encoding\n",
    "num_classes = df['category_index'].nunique()\n",
    "one_hot = F.one_hot(torch.tensor(df['category_index']).to(torch.int64), num_classes=num_classes)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f5454d2-958d-4da2-840b-e5f347186f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f04151349d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "829658da-15b4-419e-b083-e91e5603b4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1242],\n",
      "        [ 0.0574],\n",
      "        [-0.7675],\n",
      "        [-1.1242],\n",
      "        [-0.7675],\n",
      "        [ 0.0574]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "tensor([[-0.5776,  0.3355,  2.3085, -0.1005],\n",
      "        [-0.0302,  0.7318, -1.4959, -0.7707],\n",
      "        [-1.1924,  0.0649,  1.2808,  2.1736],\n",
      "        [-0.5776,  0.3355,  2.3085, -0.1005],\n",
      "        [-1.1924,  0.0649,  1.2808,  2.1736],\n",
      "        [-0.0302,  0.7318, -1.4959, -0.7707]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, num_classes, embedding_dim):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_classes, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, 1)  # Example output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding = self.embedding(x)\n",
    "        x = self.fc(embedding)\n",
    "        return x, embedding\n",
    "\n",
    "\n",
    "# Instantiate and test the model\n",
    "model = SimpleModel(num_classes=num_classes, embedding_dim=4)\n",
    "output, embeddings = model(torch.tensor(df['category_index']).to(torch.int64))\n",
    "print(output)\n",
    "print()\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986cd487-3e72-4db2-a247-12c6d9fdba11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
