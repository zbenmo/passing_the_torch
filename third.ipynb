{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b326edc-df2c-44a3-89ea-ad1f210919ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c5ed88a-0d62-4ab0-b565-5192f50fc6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2849], grad_fn=<TanhBackward0>)\n",
      "torch.Size([1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 10)\n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.tanh(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.tanh(x)\n",
    "\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "out = model(torch.rand(5))\n",
    "print(out)\n",
    "print(out.shape)\n",
    "print(model(torch.rand(5).unsqueeze(0)).shape)\n",
    "print(model(torch.rand(5).unsqueeze(0).unsqueeze(0)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059d5e3c-23ec-4ea8-ae93-a27b6153214f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0e3860b-1283-449d-877d-7c53632bdeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[ 0.4266,  0.1418,  0.0787, -0.0603, -0.1385],\n",
      "        [ 0.0955,  0.0340, -0.1283, -0.4389,  0.3964],\n",
      "        [-0.0377, -0.1160,  0.4302, -0.0834,  0.0234],\n",
      "        [ 0.2476, -0.1388,  0.1002, -0.2152, -0.4105],\n",
      "        [-0.0242,  0.1318,  0.2198,  0.1554, -0.1337],\n",
      "        [-0.0094, -0.1013,  0.1563,  0.2894, -0.1974],\n",
      "        [-0.3503, -0.0909, -0.0662,  0.2203,  0.0793],\n",
      "        [-0.1848,  0.0303, -0.3050, -0.2767, -0.2853],\n",
      "        [-0.0500,  0.3723, -0.3137,  0.1515, -0.3475],\n",
      "        [ 0.2134, -0.0008,  0.0760,  0.1344, -0.1029]])), ('bias', tensor([ 0.2230,  0.3677, -0.1096, -0.0972,  0.3266, -0.3441, -0.0099, -0.1012,\n",
      "        -0.4028,  0.2908]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "943623c5-d245-4682-926b-383d5c2c36fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f14fcd4e-5f92-4d35-aa30-588924459c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model.fc1, nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3729519-4dc8-4b93-af70-690441a28d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "writer.add_graph(model, torch.rand(5))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f486961b-860a-4dbc-b5fa-16256f30fd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Applies the Hyperbolic Tangent (Tanh) function element-wise.\n",
       "\n",
       "Tanh is defined as:\n",
       "\n",
       ".. math::\n",
       "    \\text{Tanh}(x) = \\tanh(x) = \\frac{\\exp(x) - \\exp(-x)} {\\exp(x) + \\exp(-x)}\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
       "    - Output: :math:`(*)`, same shape as the input.\n",
       "\n",
       ".. image:: ../scripts/activation_images/Tanh.png\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> m = nn.Tanh()\n",
       "    >>> input = torch.randn(2)\n",
       "    >>> output = m(input)\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initialize internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/projects/passing_the_torch/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.Tanh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aee1aa71-559e-4892-b5a4-473096cb7ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1259], grad_fn=<TanhBackward0>)\n",
      "torch.Size([1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 10)\n",
    "        self.nl1 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "        self.nl2 = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.nl1(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.nl2(x)\n",
    "\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "out = model(torch.rand(5))\n",
    "print(out)\n",
    "print(out.shape)\n",
    "print(model(torch.rand(5).unsqueeze(0)).shape)\n",
    "print(model(torch.rand(5).unsqueeze(0).unsqueeze(0)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9bf3655-38ea-4845-b43e-c20a6d9045e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "writer.add_graph(model, torch.rand(5))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32c7730a-1e7e-46fc-9eb0-023e23d4f542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.2207,  0.1466, -0.3568, -0.2860, -0.0585],\n",
       "         [-0.1582,  0.1217, -0.0859,  0.1306,  0.1662],\n",
       "         [-0.0158,  0.4182, -0.3181,  0.0978, -0.1387],\n",
       "         [ 0.1375,  0.3619,  0.2441, -0.3241, -0.0193],\n",
       "         [-0.1960,  0.4269, -0.2684,  0.0177,  0.4463],\n",
       "         [-0.1160, -0.0506, -0.2181,  0.1954,  0.2758],\n",
       "         [-0.3748,  0.1646, -0.1075, -0.1940, -0.4468],\n",
       "         [ 0.3785,  0.1593, -0.3964, -0.0366, -0.2333],\n",
       "         [ 0.1707, -0.0325, -0.0823,  0.0911, -0.3582],\n",
       "         [ 0.1998, -0.1256,  0.2642, -0.2502,  0.2250]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0451,  0.3004, -0.0041,  0.4164, -0.0115, -0.3451, -0.3801, -0.1956,\n",
       "         -0.1690,  0.3703], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.1877, -0.3158,  0.0916,  0.1542,  0.1127,  0.0930,  0.1966,  0.2425,\n",
       "           0.0706,  0.2424]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2331], requires_grad=True)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57dd62d3-7ec4-450b-ac74-ed2b3f455ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_layers=3):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layers = []\n",
    "        in_features = 5\n",
    "        out_features = 10\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.layers.append(nn.Linear(in_features, out_features))\n",
    "            in_features = out_features   \n",
    "        self.layers.append(nn.Linear(in_features, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            x = F.tanh(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5608ad47-52c9-4081-8887-f675cc1965b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e983c75c-838c-4a4a-828f-34f4ee195257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3304], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.rand(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d78b96a-5658-4e41-9ba7-4a18c039096c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layers.0.weight',\n",
       "              tensor([[ 0.3956, -0.3880,  0.4201, -0.1354, -0.1536],\n",
       "                      [ 0.1374,  0.0503,  0.0612,  0.0231,  0.1588],\n",
       "                      [-0.0798, -0.2296, -0.0735,  0.3649,  0.3362],\n",
       "                      [ 0.2273,  0.3117,  0.1105, -0.0899,  0.3984],\n",
       "                      [-0.2068, -0.1243, -0.0746, -0.0251,  0.0485],\n",
       "                      [-0.1613, -0.2822, -0.2108, -0.1591,  0.0344],\n",
       "                      [ 0.0259, -0.3709, -0.3758, -0.1356,  0.3477],\n",
       "                      [-0.3030,  0.0275, -0.3157,  0.1007,  0.2047],\n",
       "                      [-0.0222,  0.0705,  0.2005, -0.3808, -0.0279],\n",
       "                      [ 0.0557,  0.2277,  0.3824, -0.3172,  0.1456]])),\n",
       "             ('layers.0.bias',\n",
       "              tensor([ 0.2578, -0.0806,  0.1190,  0.2998,  0.2751,  0.1743,  0.2498, -0.1855,\n",
       "                      -0.3150,  0.1348])),\n",
       "             ('layers.1.weight',\n",
       "              tensor([[ 0.0866, -0.0983, -0.1061, -0.1938,  0.2220, -0.0435, -0.1673,  0.2343,\n",
       "                       -0.1903, -0.2391]])),\n",
       "             ('layers.1.bias', tensor([0.0450]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_layers=3):\n",
    "        super(MyModel, self).__init__()\n",
    "        layers = []\n",
    "        in_features = 5\n",
    "        out_features = 10\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(in_features, out_features))\n",
    "            in_features = out_features   \n",
    "        layers.append(nn.Linear(in_features, 1))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            x = F.tanh(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MyModel(2)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "851891ac-2bb9-43b8-8258-11a93e8e909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_layers=3):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layers = nn.Sequential()\n",
    "        in_features = 5\n",
    "        out_features = 10\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.layers.extend([nn.Linear(in_features, out_features), nn.Tanh()])\n",
    "            in_features = out_features   \n",
    "        self.layers.extend([nn.Linear(in_features, 1), nn.Tanh()])\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fbcb6f1-7f69-438d-9f42-c8d681f08369",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "writer.add_graph(model, torch.rand(5))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fa4d4f-c39c-43c1-a3c1-a21b59fc1317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
